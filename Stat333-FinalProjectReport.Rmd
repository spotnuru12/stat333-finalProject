---
title: "Stat 333 - Final Project Report"
author: "Kyan Cox, Kexin Wen, Shivani Potnuru"
date: "`r Sys.Date()`"
output:
  pdf_document:
    extra_dependencies: ["float"] 
header-includes:
  - \usepackage{float}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, eval = FALSE, fig.pos = "H")

library(tidyverse)  
library(jsonlite)
library(httr)
library(DBI)
library(RSQLite)
library(patchwork)
library(forcats) 
library(broom) 
```

## Major vs. Indie: Analyzing Label Impact on Billboard Hot 100 Reappearances

### Introduction

The Billboard Hot 100 is one of the most influential music charts in the U.S., representing the pinnacle of commercial success and cultural relevance in popular music. However, making an initial appearance on the chart is only the beginning; the true challenge lies in whether an artist can return to the chart, demonstrating sustained popularity. This not only reflects the appeal of the artist's work but also highlights the underlying impact of resource allocation and promotional strategies.

Within this context, a compelling question arises: Are artists signed to major record labels more likely to reappear on the Billboard Hot 100 than their independent counterparts? Major labels such as Universal, Sony, and Warner typically possess greater financial resources and promotional infrastructure, which in theory could help sustain an artists visibility. However, with the rise of digital platforms and social media, an increasing number of independent artists have managed to gain widespread recognition through online channels alone.

Using historical data from the Billboard Hot 100, this study investigates whether artists signed to major labels have a statistically significant advantage in reappearing on the chart after their initial breakout—even after controlling for variables such as initial chart position, musical genre, and release timing. Our analysis indicates that affiliation with a major label is associated with only a slight increase in the likelihood of reappearance. In contrast, factors such as the debut song’s initial performance and genre exert a more substantial influence on an artist’s sustained visibility. These findings challenge conventional assumptions regarding the predominant role of major-label backing and offer important implications for resource allocation and promotional strategies within the American music industry.

### Methods

To determine whether artists affiliated with major record labels have a higher likelihood of repeatedly appearing on the Billboard Hot 100, we integrated multiple publicly accessible datasets. Our primary data source consisted of Billboard Year-End Hot 100 charts from 1970 to 2024, gathered through web scraping Wikipedia pages ([e.g., Billboard Year-End Hot 100 Singles of 1995](https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1995)). This initial dataset contained roughly 5,400 entries, each including the rank ("No."), song title, artist(s), and year.

Since our research focuses on sustained popularity after an initial breakthrough, we condensed the data to a single record per artist. We tokenized the `Artist(s)` field by common delimiters (e.g., commas, "feat.", "&", "x"), designating the first token as the `primary_artist`. If an artist had multiple debut songs in the same year, we retained only the highest-ranking song as their initial appearance, with subsequent songs classified as reappearances. After these adjustments, our final dataset comprised 2,042 unique artist-song pairs. We derived two key indicators: `is_first_appearance` (a binary indicator marking initial appearances) and `reappearance_count` (defined as the total appearances minus one).

To accurately categorize artists by their record label type ("Major" or "Indie"), we queried each debut track via the Spotify Web API ([Spotify Web API](https://developer.spotify.com/)) using the spotifyr R package. For each track, Spotify provided: (1) the official label name(s), (2) track duration (`duration_sec`), and (3) release date, which was used for validation (e.g., identifying reissues or remastered tracks). Label names were standardized through lower-casing, punctuation removal, and trimming whitespace. Standardized labels were then cross-referenced with major-label lists compiled from Wikipedia and industry histories for each decade, also considering sub-label affiliations (e.g., Rhino Atlantic under Warner). This process yielded a binary variable, `is_major_label`, classifying 478 debut artists as "Major" and 1,564 as "Indie."

Recognizing the importance of genre in predicting sustained popularity, we annotated each track with a genre label by integrating metadata from the Million Song Dataset (MSD) and the Tagtraum genre annotations. Specifically, we leveraged the [msd_tagtraum_cd2.cls](https://www.tagtraum.com/msd_genre_datasets.html) file, which maps over 900,000 unique `track_ids` from the MSD to one of 16 genre categories. To match our Billboard dataset to these genre annotations, we first cleaned and normalized both song titles and artist names, and then attempted to join them to the MSD’s track metadata database, which contains track_id, title, and artist_name for all tracks in the collection. Matching was conducted in two stages. We first performed exact string joins between our cleaned Billboard entries and MSD metadata. For any records that remained unmatched, we used fuzzy string matching (with a maximum Levenshtein distance of 2) to link the most similar MSD entries based on title and artist name. Once a match was established, we used the track_id to merge in the Tagtraum genre label. Because the MSD largely covers music released before 2010, many recent Billboard entries were not represented in the dataset. To fill these genre gaps, we queried the Last.fm API for each unmatched track, retrieving the top five user-generated tags. We then selected the highest-ranking tag that matched one of Tagtraum’s predefined genres. After deduplication, giving priority to MSD labels when available, approximately 8% of debut tracks remained labeled as “Unknown”, meaning no reliable match could be found in either dataset.

Our primary outcome variable, `reappearance_count`, exhibited substantial right-skewness, with many artists never reappearing after their initial chart debut. To manage this skewness and effectively model the data, we applied a logarithmic transformation: log_reappearance = log(reappearance_count + 1). This transformation maintained the interpretability of zero reappearances (one-hit wonders).

We employed ordinary least squares (OLS) regression for our analysis, modeling log-transformed reappearances as follows:

```{r, eval = TRUE}
log_reappearance ~ is_major_label + No. + decade + duration_sec + genre
```

Here, No. represents initial chart position (1 being the highest), chosen to control for initial commercial success; genre adjusts for listener-base loyalty; duration_sec indirectly captures streaming and radio-friendliness; and decade serves as a categorical fixed effect accounting for systemic industry changes across time. When running linear regression, categorical variables required explicit baseline categories. For the decade variable, we chose the 1970s as the baseline, allowing interpretation of regression coefficients for subsequent decades relative to this earlier period. Similarly, for genre, we selected 'Unknown' as the reference category, ensuring all known genres were consistently compared against those not categorized.

Figure 1 visually represents the distribution of log-transformed reappearance counts, split by label type. We opted for a percentage to account of the large variation in counts between both categories. Both distributions display prominent peaks at zero, indicating many one-hit wonders, and overall similarity between major-label and indie artists. These visual patterns align with our hypothesis that major-label affiliation alone does not significantly predict sustained Billboard Hot 100 success.

```{r fig1, fig.cap="Distribution of log-transformed re-appearance counts for first-time Billboard Hot 100 artists by label type (n = 478 major-label, n = 1,564 indie). The spike at zero shows all the one-hit wonders.", fig.pos='H',message=FALSE, warning=FALSE,echo=FALSE, fig.align='center',fig.width=5.5,fig.asp=0.35, eval = TRUE}
library(patchwork)

df <- read_csv("billboard_top100_with_top_tag3.csv") %>%
  mutate(
    reappearance_count = coalesce(reappearance_count, sqrt_reappearance^2, 0),
    log_reappearance   = log(reappearance_count + 1),
    label_type         = if_else(is_major_label, "Major", "Indie")
  )

plot_hist <- function(d, ttl) {
  ggplot(d, aes(log_reappearance)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 30, fill="steelblue", color="grey30", alpha=.8) +
    scale_y_continuous(labels = scales::percent) +
    coord_cartesian(xlim = c(0,3)) +
    labs(title = ttl, x="log(reappearance + 1)", y="% of artists") +
    theme_minimal()
}

p1 <- plot_hist(filter(df, label_type=="Major"), "Major-label artists")
p2 <- plot_hist(filter(df, label_type=="Indie"),     "Indie artists")

p1 | p2
```

Detailed procedures for data scraping, matching, label classification, and genre annotation are available and replicable via R scripts provided in the accompanying .Rmd file.

### Results

We fit a linear model predicting log_reappearance using label affiliation, chart position, decade, genre, and track duration. The overall model was statistically significant (F(22, 2019) = 6.21, p < 0.001) but explained only a small portion of the variation in reappearance counts (Adjusted R² $\approx$ 5.3%), consistent with the view that many other artist-level or industry-level factors influence sustained popularity beyond those included in this model.

```{r results, eval = TRUE}
library(broom)

df <- read_csv("billboard_top100_with_top_tag3.csv", show_col_types = FALSE) %>%
  mutate(
    genre = factor(replace_na(lastfm_genre, "Unknown")),
    genre = relevel(genre, ref = "Unknown"),
    is_major_label = factor(is_major_label, levels = c(FALSE, TRUE), labels = c("Indie", "Major")),
    decade = factor(decade),
    log_reappearance = log(reappearance_count + 1)
  )

mod_simple <- lm(log_reappearance ~ is_major_label + No. + decade + duration_sec + genre, data = df)

tidy(mod_simple, conf.int = TRUE) %>%
  mutate(across(where(is.numeric), \(x) round(x, 3))) %>%
  knitr::kable(caption = "Table 1: Coefficients from OLS model predicting log(reappearance + 1).")
```

Major-label affiliation had a small but statistically significant effect: artists signed to major labels were predicted to have about 9% higher reappearance counts than indie artists, controlling for all other variables ($\beta \approx 0.089$, $p = 0.029$). However, the strongest predictor in the model was initial chart position. Artists who debuted higher on the chart were significantly more likely to return to it, even after adjusting for genre and decade. Some genre effects were also notable—RnB and Pop showed elevated return rates—but genre was generally a noisier variable due to inconsistent classification. Songs from the 2010s slightly outperformed the 1970s baseline in terms of reappearance, whereas those from the 2020s underperformed, possibly due to recency bias (i.e., not enough time has passed to observe reappearances).

To evaluate model assumptions, we examined four standard diagnostic plots. The Residuals vs. Fitted plot revealed mild heteroscedasticity—residual spread increased at higher fitted values—suggesting non-constant variance, a violation of OLS assumptions. The Normal Q-Q plot showed modest right-tail deviation, indicating that extreme values were slightly heavier-tailed than assumed under normality. The Scale-Location plot echoed the heteroscedasticity issue, with variance spreading more as fitted values increased. Lastly, the Residuals vs. Leverage plot identified a few moderately influential points but no clear outliers with extreme leverage. Together, these diagnostics suggest that while the model provides useful estimates and interpretable coefficients, it may benefit from a transformation of variables or the use of a more flexible modeling approach.

```{r regression diagnostic plots, fig.cap="Figure 2: OLS regression diagnostic plots: (1) Residuals vs Fitted, (2) Normal Q-Q, (3) Scale-Location, (4) Residuals vs Leverage.", fig.width=4.5, fig.height=4.5, fig.align='center', echo=FALSE, message=FALSE, warning=FALSE, fig.pos='H', eval=TRUE}
par(mfrow = c(2, 2), mar = c(4, 4, 2, 1))
plot(mod_simple)
```

### Conclusion

This study examined a common assumption: that artists signed to major record labels are more likely to reappear on the Billboard Hot 100 following their initial chart entry. Regression analysis reveals that after controlling for initial chart position, release decade, song duration, and genre, affiliation with a major label does exhibit a statistically significant but relatively modest positive association with repeated appearances (p = 0.0285). Although statistically significant, the small effect size (approximately 0.09 on a log scale) suggests that while major labels have an advantage, it is not overwhelmingly decisive in predicting long-term chart success. In contrast, other variables play a more pivotal role. Initial chart position emerges as the strongest predictor, showing a significant positive association with reappearance likelihood, suggesting that the initial impact of a song is critical to an artists continued visibility. Additionally, both genre and release decade exhibit meaningful trends: for instance, RnB tracks and songs released in the 2010s are more likely to re-enter the chart, whereas those from the 2020s are less likely to do so.

However, this study also presented several limitations that need to be considered. The linear regression model demonstrated a relatively low degree of explanatory power (adjusted R² \~ 5.3%), indicating that important influencing factors were likely omitted. In terms of data quality, genre classification based on Last.fm tags may have introduced considerable noise, especially with the increasing prevalence of "Unknown" tags in recent years, which diminish the reliability of genre as a variable. Meanwhile, the classification of labels as "major" or "independent" is complicated by decades of industry consolidation and ownership changes, making categorization across time difficult. The analysis also focused solely on primary artists, potentially underestimating the role of featured collaborators in contributing to a songs success. Additionally, more recent Billboard entries may not have had sufficient time to exhibit reappearance behavior, which could bias the results in favor of earlier releases. Diagnostic tests further suggested violations of key linear model assumptions, such as non-linearity and heteroscedasticity, indicating that alternative approaches like non-linear modeling or survival analysis may better capture reappearance dynamics. These limitations provide valuable insights for future research, highlighting the need to improve research methods, incorporate more variables, and explore more appropriate modeling approaches

This study carries practical implications for stakeholders in the music industry. Relying solely on label affiliation as a guarantee of sustained success might be misguided. Instead, a songs intrinsic appeal, particularly its initial impact and its compatibility with contemporary cultural and musical trends, plays a more decisive role in an artist's long-term visibility on the Billboard charts. Future research could refine the classification of record labels, incorporate multidimensional variables such as marketing expenditures, social media engagement, and streaming metrics, and adopt alternative modeling techniques better suited to the complexities of chart performance. Enhancing the precision of genre categorization may also contribute to more robust analytical outcomes. In conclusion, this study suggests that while major record labels hold distinct advantages, continued chart success is a multifaceted phenomenon, where song's initial impact and its resonance with audience preferences are more statistically significant than label type.

### Works Cited

- Billboard Year-End Hot 100 Singles pages. Wikipedia. https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles

- Spotify Web API. Spotify Developers. https://developer.spotify.com/documentation/web-api/

- Last.fm API. Last.fm. https://www.last.fm/api

- Bertin-Mahieux, T., Ellis, D. P. W., Whitman, B., & Lamere, P. (2011). The Million Song Dataset. Proceedings of the 12th International     Society for Music Information Retrieval Conference (ISMIR 2011). http://millionsongdataset.com

- Schreiber, H., & Müller, M. (2011). Tagtraum genre annotations. Tagtraum Industries. https://www.tagtraum.com/msd_genre_datasets.html




```{r dataset creation}
# all code used to create final data set

# ------------------- SCRAPING THE BILLBOARD END OF YEAR HOT 100 --------------------------

scrape_year <- function(year) {
  url <- paste0("https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_", year)
  page <- read_html(url)
  
  table_node <- page %>% html_node("table.wikitable")
  
  # if no table found; return NULL
  if (is.null(table_node)) {
    warning(paste("No table found for", year))
    return(NULL)
  }
  df <- table_node %>% html_table(fill = TRUE)
  
    if (ncol(df) > 0) {
    names(df)[1] <- "No."
    }
  
  df$Year <- year
  return(df)
}

years <- 1970:2024

all_data <- map_dfr(years, function(y) {
  message("Scraping ", y, "...")
  scraped <- tryCatch(scrape_year(y), error = function(e) NULL)
  scraped
})

# organizing to arrange by year
if ("№" %in% colnames(all_data)) {
  all_data <- all_data %>% rename(No. = `№`)
}

if ("Artist(s)" %in% colnames(all_data)) {
  all_data <- all_data %>% rename(Artist = `Artist(s)`)
}

# ensure correct data type
all_data <- all_data %>% mutate(`No.` = as.integer(`No.`))

# possible chars that represent a split between two artists
sep_rx2 <- regex(
  "(?i)\\s*(?:,|&|\\bfeaturing\\b|\\bfeat\\.?\\b|\\bwith\\b|\\bvs?\\.?\\b| and (?!the\\b)| x )\\s*"
)

# preserve original artist string
rank_by_year <- all_data %>%
  mutate(
    Artist      = tolower(Artist) %>% str_trim(),
    all_artists = Artist,
    # separating the artists 
    artist_list = str_split(Artist, sep_rx2)
  ) %>%
  mutate(
    primary_artist = map_chr(artist_list, 1) %>% str_squish(),
    other_artists  = map_chr(
      artist_list,
      ~ {
        tmp <- discard(.x[-1], ~ .x == "")
        if (length(tmp)==0) return(NA_character_)
        paste(tmp, collapse = ", ")
      }
    )
  ) %>%
  group_by(primary_artist) %>%
  mutate(
    primary_artist_count = n(),
    one_hit              = ifelse(n()==1, 1, 0)
  ) %>%
  ungroup()

# final data w/ selected cols 
final_data <- rank_by_year %>%
  select(
    No., Title, Year,
    Artist,          
    artist_list,      
    primary_artist,
    primary_artist_count,
    one_hit
  )

# calculating the amount of times an artist appeared 
artist_total_counts <- final_data %>%
  count(primary_artist, name = "total_appearances")

artist_first_appearance <- final_data %>%
  arrange(Year, `No.`) %>%
  group_by(primary_artist) %>%
  slice_head(n = 1) %>%
  ungroup() %>%
  select(primary_artist, Year, Title) %>%
  mutate(is_first_appearance = TRUE)

# including first appearance field 
new_final_data <- final_data %>%
  left_join(artist_total_counts, by = "primary_artist") %>%
  left_join(artist_first_appearance %>% mutate(flag_first = TRUE),
            by = c("primary_artist", "Year", "Title")) %>%
  mutate(
    is_first_appearance = ifelse(is.na(flag_first), FALSE, TRUE)
  ) %>%
  select(
    primary_artist, Year, Title,
    artist_list,
    is_first_appearance,
    total_appearances
  )

write_csv(final_data, "finalData.csv") # this file has placements


# ----------------- SPOTIFY API FOR LABELS & DURATION -----------------------

install.packages("spotifyr", repos="https://cloud.r-project.org/")
install.packages("progress")

library(spotifyr)
library(tidyverse)
library(progress)

# replace with your own API key
Sys.setenv(
  SPOTIFY_CLIENT_ID     = "REPLACE WITH YOUR API KEY",
  SPOTIFY_CLIENT_SECRET = "REPLACE WITH YOUR SLIENT SECRET"
)
access_token <- get_spotify_access_token()

get_label_and_date <- function(song_title, artist_name) {
  tryCatch({
    Sys.sleep(1.5)
    results <- search_spotify(paste(song_title, artist_name),
                              type = "track", limit = 5)
    if (nrow(results) == 0)
      return(list(label = NA_character_, date = NA_character_))

    results <- results %>%
      filter(!is.na(album.release_date)) %>%
      arrange(album.release_date)

    alb <- get_album(results$album.id[1])
    list(label = alb$label, date = alb$release_date)
  }, error = function(e) list(label = NA_character_, date = NA_character_))
}

# split into 500-row batches to avoid losing data
chunk_size <- 500
n          <- nrow(new_final_data)
chunk_ids  <- ceiling(seq_len(n) / chunk_size)

# detect batches already saved so we can resume
done_chunks <- list.files(pattern = "^batch_labels_\\d{3}\\.csv$") |>
               stringr::str_extract("\\d{3}") |>
               as.integer()

batch_results <- vector("list", length = max(chunk_ids))

for (i in setdiff(seq_len(max(chunk_ids)), done_chunks)) {
  full_data <- new_final_data %>% filter(chunk_ids == i)

  # progress bar to keep track
  pb <- progress_bar$new(
    total  = nrow(full_data),
    format = paste0("Batch ", i, " [:bar] :current/:total ",
                    "(:percent) Elapsed: :elapsed"),
    clear  = FALSE
  )

  label_info_list <- map2(full_data$Title, full_data$primary_artist,
                          function(t, a) { pb$tick(); get_label_and_date(t, a) })

  batch_out <- full_data %>%
    mutate(
      artist_list  = map_chr(artist_list,
                             jsonlite::toJSON,
                             auto_unbox = TRUE),
      label_info   = label_info_list,
      record_label = map_chr(label_info, "label"),
      album_year   = map_chr(label_info, "date")
    ) %>%
    select(-label_info)

  write_csv(batch_out, sprintf("batch_labels_%03d.csv", i))
  batch_results[[i]] <- batch_out
}

# combine all batches (new + previously finished)
final_combined <- list.files(pattern = "^batch_labels_\\d{3}\\.csv$") |>
                  map_dfr(readr::read_csv, show_col_types = FALSE)

write_csv(final_combined, "STAT333_full_with_labels.csv")

# -------------------- CATEGORIZING AS MAJOR LABEL ----------------------------

# Make sure to use setwd() in the terminal first before running this.

# load the dataset from previous code 
df <- read_csv("STAT333_full_with_labels.csv") 

# count unique values in the record_label column
unique_labels <- df %>%
  distinct(record_label) %>%
  pull(record_label)

# print the unique labels
cat("Number of unique record labels:", length(unique_labels), "\n\n")
print(unique_labels)

# mutate new column
df <- df %>%
  mutate(
    record_label_list = str_split(record_label, pattern = "\\s*/\\s*")
  )

# recognizes lowercase & trimmed (columbia vs columbia records) 
major_labels_list <- list(
  `1970s` = c("rca records", "columbia records", "capitol records", "columbia",
              "atlantic records", "motown", "emi records", "island records",
              "polygram", "warner records", "mca records",
              # sub-labels / catalog divisions showing up in your data
              "rhino", "rhino atlantic", "legacy", "uni"),
  
  `1980s` = c("rca records", "columbia records", "capitol records", "columbia",
              "atlantic records", "motown", "emi records", "island records",
              "polygram", "sony music entertainment", "warner music group",
              "mca records",
              # catalog & reissue labels
              "rhino", "rhino atlantic", "legacy", "uni"),
  
  `1990s` = c("universal music group", "sony music entertainment",
              "warner music group", "bertelsmann music group", "emi records",
              "island records", "polygram", "mca records",
              # big-three sub-labels
              "rhino", "legacy","arista", "a&m"),
  
  `2000s` = c("universal music group", "sony music entertainment",
              "warner music group", "emi", "bmg", 
              # modern imprint sub-labels
              "interscope records",
              "def jam recordings", "jive", "atlantic records", "geffen", "epic"),
  
  `2010s` = c("universal music group", "sony music entertainment",
              "warner music group", 
              # today’s big-three imprints
              "interscope records", "def jam recordings",
              "republic records", "ovo sound", "aftermath", "jive", "geffen",
              "epic", "rca records"),
  
  `2020s` = c("universal music group", "sony music entertainment",
              "warner music group", 
              # current sub-labels you saw in your 2020s top-10
              "interscope records", "def jam recordings",
              "republic records", "ovo sound", "aftermath", "kemosabe records",
              "mercury records", "atlantic records", "epic", "rca records")
)

# normalize all lookup values
major_lookup_clean <- map(major_labels_list, ~ str_trim(str_to_lower(.x)))

# update each row if ANY of its record_label_list is in the decade’s majors
df_flagged <- df %>%
  mutate(decade = paste0(floor(Year / 10) * 10, "s")) %>%
  rowwise() %>%
  mutate(
    is_major_label = any(
      str_trim(str_to_lower(record_label_list)) %in% major_lookup_clean[[decade]]
    )
  ) %>%
  ungroup()

# split record label list by x; y; z
df_with_record_label <- df_flagged %>%
  mutate(
    record_label_list = map_chr(record_label_list, ~ str_c(.x, collapse = "; "))
  )

write_csv(df_with_record_label, "data-with-major-label-binary-cleaned.csv")

# ------------------ ADDING PLACEMENT COLUMN ----------------------------------

# has placements column
df_placements <- read_csv("finalData.csv") 
# file generated with record label classifications
df_major_label <- read_csv("data-with-major-label-binary-cleaned.csv") 

df <- df_major_label %>%
  filter(is_first_appearance) %>%
  left_join(
    df_placements %>% select(Title, Year, primary_artist, No.),
    by = c("Title", "Year", "primary_artist")
  ) %>%
  mutate(
    # squaring reappearance count
    reappearance_count  = total_appearances - 1,
    sqrt_reappearance = sqrt(reappearance_count),
    
    reappears_after_first = reappearance_count > 0
  )

readr::write_csv(df, "new_data_with_placements.csv")

#-------------------  GENRE TAGGING w/ MSD Tagtraum ---------------------------

# load and filter billboard Top 40 data. 
df <- read_csv("new_data_with_placements.csv", show_col_types = FALSE) %>%
  # filter(No. >= 1 & No. <= 40) %>%
  mutate(row_id = row_number())

# Load MSD metadata and genre; make sure you have db in wd 
con <- dbConnect(SQLite(), "track_metadata.db")
track_metadata <- dbGetQuery(con, "SELECT track_id, title, artist_name FROM songs")

genre_df <- read_delim(
  "msd_tagtraum_cd2.cls",
  delim = "\t",
  col_names = FALSE,
  comment = "#",
  show_col_types = FALSE
) %>%
  rename(track_id = X1, genre = X2)

# clean strings for matching
clean_string <- function(x) {
  x %>%
    tolower() %>%
    str_replace_all("&", "and") %>%
    str_replace_all("[“”\"']", "") %>%
    str_replace_all("[^a-z0-9 ]", "") %>%
    str_squish()
}

df_clean <- df %>%
  mutate(title_clean = clean_string(Title),
         artist_clean = clean_string(primary_artist))

track_clean <- track_metadata %>%
  mutate(title_clean = clean_string(title),
         artist_clean = clean_string(artist_name))

# exact match
exact_matches <- df_clean %>%
  left_join(track_clean, by = c("title_clean", "artist_clean")) %>%
  filter(!is.na(track_id)) %>%
  select(row_id, track_id)

# fuzzy match (only for unmatched)
unmatched <- df_clean %>% filter(!(row_id %in% exact_matches$row_id))

fuzzy_matches <- stringdist_inner_join(
  unmatched, track_clean,
  by = c("title_clean", "artist_clean"),
  max_dist = 2,
  distance_col = "dist"
) %>%
  group_by(row_id) %>%
  slice_min(dist, n = 1, with_ties = FALSE) %>%
  ungroup() %>%
  select(row_id, track_id)

# combine matches and join genre
track_matches <- bind_rows(exact_matches, fuzzy_matches)

df_matched <- df_clean %>%
  left_join(track_matches, by = "row_id") %>%
  left_join(genre_df, by = "track_id")

# SDeduplicate — keep one row per (Title, primary_artist), preferring genre not NA
df_deduped <- df_matched %>%
  group_by(Title, primary_artist) %>%
  arrange(is.na(genre)) %>%
  slice(1) %>%
  ungroup()

# save results
write_csv(df_deduped, "billboard_top100_cleaned_genre.csv")

# summary
df_deduped %>% count(Matched = !is.na(genre))

# ---------------------- LASTFM TO FILL IN GAPS -------------------------------

# insert your own LASTFM API key
LASTFM_API_KEY <- "INSERT LASTFM API KEY"
allowed_genres <- c(
  "Blues", "Country", "Electronic", "Folk", "Jazz", "Latin", "Metal", "New Age", "Pop",
  "Punk", "Rap", "Reggae", "RnB", "Rock", "World"
) %>%
  tolower() %>%
  str_replace_all("/", " ")

# look for allowed genre within top 5 tags
get_lastfm_genre_from_top5 <- function(artist, track) {
  url <- modify_url(
    "http://ws.audioscrobbler.com/2.0/",
    query = list(
      method  = "track.getTopTags",
      api_key = LASTFM_API_KEY,
      artist  = artist,
      track   = track,
      format  = "json"
    )
  )
  
  txt <- tryCatch(
    GET(url) %>% stop_for_status() %>% content("text", encoding = "UTF-8"),
    error = function(e) NA_character_
  )
  if (is.na(txt)) return(NA_character_)
  
  tags <- fromJSON(txt, simplifyDataFrame = TRUE)$toptags$tag
  if (is.null(tags) || nrow(as_tibble(tags)) == 0) return(NA_character_)
  
  nm <- tolower(tags$name) %>%
    str_replace_all("/", " ") %>%
    .[1:min(5, length(.))]  # Limit to top 5
  
  allowed_match <- nm[nm %in% allowed_genres]
  if (length(allowed_match) == 0) return(NA_character_)
  
  str_to_title(allowed_match[1])
}

# load & prep data 
df <- read_csv("billboard_top100_cleaned_genre.csv", show_col_types = FALSE) %>%
  mutate(
    clean_title   = str_remove_all(Title, '"'),
    search_artist = map_chr(artist_list, ~ {
      a <- tryCatch(fromJSON(.x), error = function(e) primary_artist)
      paste(a, collapse = " & ")
    }),
    new_lastfm_genre = NA_character_
  )

#  fill genre if one of top 5 tags is allowed 
to_fill <- which(is.na(df$new_lastfm_genre))
message("Checking top 5 tags for ", length(to_fill), " tracks...")

pb <- progress_bar$new(
  total = length(to_fill),
  format = " Fetching [:bar] :current/:total (:percent) ETA: :eta"
)

for (i in to_fill) {
  pb$tick()
  Sys.sleep(0.5)
  df$new_lastfm_genre[i] <- get_lastfm_genre_from_top5(df$search_artist[i], df$clean_title[i])
}

# save result to file
write_csv(df, "billboard_top100_with_top_tag3.csv")
```
